{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Beginning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "import subprocess\n",
    "import os.path\n",
    "import time\n",
    "import math\n",
    "import csv\n",
    "#%matplotlib inline\n",
    "    \n",
    "from sklearn.datasets import make_regression, make_classification, load_iris\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "from keras.models import Sequential, Model, load_model\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten, Conv2D, MaxPooling2D\n",
    "from keras.utils import to_categorical,np_utils\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "#Function from Alex Lin \n",
    "def bash(string):\n",
    "    '''run a bash command and return stdout lines as a py list'''\n",
    "    stdout=(subprocess.Popen(string, shell=True, stdout=subprocess.PIPE).stdout.read())\n",
    "    output = str(stdout)[2:-1].split('\\\\n')[:-1]\n",
    "    #output = str(stdout).split('\\\\n')[1:-1]\n",
    "    #output[0] = output[0][2:]\n",
    "    return output\n",
    "\n",
    "# Get all the spectrograms in the Data Folder\n",
    "# then put in a numpy array\n",
    "# Get labels too"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(data_folder, divisor, start_at = \"none\", stop = \"none\"):\n",
    "    lis = bash('ls '+ data_folder)\n",
    "    \n",
    "    start_flag = 0\n",
    "    img_array = []\n",
    "    labels = []\n",
    "    \n",
    "    if start_at == \"none\":\n",
    "        start_flag = 1\n",
    "\n",
    "    for path in lis:\n",
    "        path_ = data_folder+ path\n",
    "        \n",
    "        if path_ == start_at:\n",
    "            start_flag = 1\n",
    "        \n",
    "        if start_flag == 0:\n",
    "            continue\n",
    "\n",
    "        if path_ == stop:\n",
    "            break;\n",
    "\n",
    "        img = cv2.imread(path_,0)\n",
    "        img_norm = img/255\n",
    "        img_norm.resize(int(513/divisor),int(800/divisor))\n",
    "        img_array.append(img_norm)\n",
    "        labels.append(path[0:6])\n",
    "    return img_array, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_img_array_to_X(img_array):\n",
    "    np.array(img_array)\n",
    "    return np.array(img_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def labels_onehot(labels):\n",
    "    le = LabelEncoder()\n",
    "    y_cat = le.fit_transform(labels)\n",
    "    y_cat = y_cat.reshape(-1,1)\n",
    "    \n",
    "    ohe = OneHotEncoder()\n",
    "    y_cat = ohe.fit_transform(y_cat).toarray()\n",
    "    \n",
    "    return y_cat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X2 ,y2 = load_data(data_folder=\"../Data/\", divisor = 2,start_at = 'none',stop = 'none')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "y2 = labels_onehot(y2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X2 = convert_img_array_to_X(X2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X2 = X2.reshape(X2.shape[0],256,400,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(23360, 256, 400, 1)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train2, X_test2, y_train2, y_test2 = train_test_split(X2,y2,test_size = 0.1,stratify = y2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('X2.npy', X2)\n",
    "np.save('y2.npy', y2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X2 = np.load('X2.npy')\n",
    "y2 = np.load('y2.npy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = Sequential()\n",
    "\n",
    "model2.add(Conv2D(filters = 16,                   # number of filters\n",
    "                         kernel_size = 3,        # height/width of filter\n",
    "                         padding = \"same\",\n",
    "                         activation='relu',      # activation function \n",
    "                         input_shape=(X2[0].shape))) # shape of input (dimensions of training image)\n",
    "\n",
    "model2.add(Conv2D(16, kernel_size = 3, activation='relu'))\n",
    "model2.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model2.add(Dropout(0.5))\n",
    " \n",
    "model2.add(Conv2D(16, kernel_size = 3, activation='relu'))\n",
    "model2.add(Conv2D(16, kernel_size = 3, activation='relu'))\n",
    "model2.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model2.add(Dropout(0.25))\n",
    "\n",
    "model2.add(Flatten())\n",
    "model2.add(Activation('relu'))\n",
    "model2.add(Dense(y2.shape[1], activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_9 (Conv2D)            (None, 256, 400, 16)      160       \n",
      "_________________________________________________________________\n",
      "conv2d_10 (Conv2D)           (None, 254, 398, 16)      2320      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2 (None, 127, 199, 16)      0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 127, 199, 16)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_11 (Conv2D)           (None, 125, 197, 16)      2320      \n",
      "_________________________________________________________________\n",
      "conv2d_12 (Conv2D)           (None, 123, 195, 16)      2320      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2 (None, 61, 97, 16)        0         \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 61, 97, 16)        0         \n",
      "_________________________________________________________________\n",
      "flatten_3 (Flatten)          (None, 94672)             0         \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 94672)             0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 55)                5207015   \n",
      "=================================================================\n",
      "Total params: 5,214,135\n",
      "Trainable params: 5,214,135\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "earlystop = EarlyStopping(monitor='val_acc', min_delta=0.0001, patience=7,verbose=1, mode='auto')\n",
    "callbacks_list = [earlystop]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 21024 samples, validate on 2336 samples\n",
      "Epoch 1/100\n",
      "21024/21024 [==============================] - 168s 8ms/step - loss: 2.5827 - acc: 0.3066 - val_loss: 1.5903 - val_acc: 0.5223\n",
      "Epoch 2/100\n",
      "21024/21024 [==============================] - 160s 8ms/step - loss: 0.8390 - acc: 0.7457 - val_loss: 1.0069 - val_acc: 0.6991\n",
      "Epoch 3/100\n",
      "21024/21024 [==============================] - 161s 8ms/step - loss: 0.2672 - acc: 0.9191 - val_loss: 1.0823 - val_acc: 0.7055\n",
      "Epoch 4/100\n",
      "21024/21024 [==============================] - 161s 8ms/step - loss: 0.0726 - acc: 0.9785 - val_loss: 1.0063 - val_acc: 0.7526\n",
      "Epoch 5/100\n",
      "21024/21024 [==============================] - 161s 8ms/step - loss: 0.0505 - acc: 0.9846 - val_loss: 1.1124 - val_acc: 0.7470\n",
      "Epoch 6/100\n",
      "21024/21024 [==============================] - 161s 8ms/step - loss: 0.0537 - acc: 0.9846 - val_loss: 1.4129 - val_acc: 0.7046\n",
      "Epoch 7/100\n",
      "21024/21024 [==============================] - 161s 8ms/step - loss: 0.0417 - acc: 0.9873 - val_loss: 1.6654 - val_acc: 0.6781\n",
      "Epoch 8/100\n",
      "21024/21024 [==============================] - 161s 8ms/step - loss: 0.0340 - acc: 0.9902 - val_loss: 1.7006 - val_acc: 0.6580\n",
      "Epoch 9/100\n",
      "21024/21024 [==============================] - 161s 8ms/step - loss: 0.0211 - acc: 0.9935 - val_loss: 1.6368 - val_acc: 0.7106\n",
      "Epoch 10/100\n",
      "21024/21024 [==============================] - 161s 8ms/step - loss: 0.0298 - acc: 0.9899 - val_loss: 1.8338 - val_acc: 0.6832\n",
      "Epoch 11/100\n",
      "21024/21024 [==============================] - 161s 8ms/step - loss: 0.0370 - acc: 0.9896 - val_loss: 1.6579 - val_acc: 0.7093\n",
      "Epoch 00011: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f075f4e1208>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2.fit(X_train2, y_train2, epochs=100, verbose=1, validation_data=(X_test2,y_test2),callbacks=callbacks_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[42,  0,  0, ...,  0,  0,  0],\n",
       "       [ 0, 25,  0, ...,  1,  0,  1],\n",
       "       [ 0,  0, 13, ...,  0,  0,  4],\n",
       "       ...,\n",
       "       [ 0,  0,  0, ..., 38,  0,  1],\n",
       "       [ 1,  0,  0, ...,  0, 26,  0],\n",
       "       [ 0,  0,  0, ...,  3,  0, 24]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = model2.predict_classes(X_test2) \n",
    "y_test2_class= [np.where(r==1)[0][0] for r in y_test2]\n",
    "\n",
    "confusion_matrix( y_test2_class, predictions )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2.save('model_grayscale_55ppl_v3.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Different Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(filters = 64,                   # number of filters\n",
    "                         kernel_size = 5,        # height/width of filter\n",
    "                         padding = \"same\",\n",
    "                         activation='relu',      # activation function \n",
    "                         input_shape=(X2[0].shape))) # shape of input (dimensions of training image)\n",
    "\n",
    "model.add(Conv2D(64, kernel_size = 5, activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.25))\n",
    " \n",
    "model.add(Conv2D(64, kernel_size = 3, activation='relu'))\n",
    "model.add(Conv2D(32, kernel_size = 3, activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(y2.shape[1], activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 256, 400, 64)      1664      \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 252, 396, 64)      102464    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 126, 198, 64)      0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 126, 198, 64)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 124, 196, 64)      36928     \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 122, 194, 32)      18464     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 61, 97, 32)        0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 189344)            0         \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 189344)            0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 64)                12118080  \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 55)                3575      \n",
      "=================================================================\n",
      "Total params: 12,281,175\n",
      "Trainable params: 12,281,175\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "earlystop = EarlyStopping(monitor='val_acc', min_delta=0.0001, patience=7,verbose=1, mode='auto')\n",
    "callbacks_list = [earlystop]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 21024 samples, validate on 2336 samples\n",
      "Epoch 1/100\n",
      "21024/21024 [==============================] - 564s 27ms/step - loss: 4.0045 - acc: 0.0206 - val_loss: 4.0014 - val_acc: 0.0218\n",
      "Epoch 2/100\n",
      "21024/21024 [==============================] - 555s 26ms/step - loss: 4.0007 - acc: 0.0220 - val_loss: 3.9993 - val_acc: 0.0218\n",
      "Epoch 3/100\n",
      "15744/21024 [=====================>........] - ETA: 2:14 - loss: 3.9993 - acc: 0.0225"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-af18468b5c10>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_test2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallbacks_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1037\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1038\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1039\u001b[0;31m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1040\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1041\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m    197\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    200\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2713\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2714\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2715\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2716\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2717\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2674\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2675\u001b[0;31m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2676\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1397\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[1;32m   1398\u001b[0m               \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1399\u001b[0;31m               run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1400\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1401\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train2, y_train2, epochs=100, verbose=1, validation_data=(X_test2,y_test2),callbacks=callbacks_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2.save('model_grayscale_55ppl_v2.h5')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
